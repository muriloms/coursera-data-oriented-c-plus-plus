# ApresentaÃ§Ã£o do MÃ³dulo: Algoritmos Paralelos - Material de Estudo Completo

## ğŸ“ˆ A EvoluÃ§Ã£o HistÃ³rica da Performance

### O GrÃ¡fico Revelador (1995-2020)

```
Performance (log)
   â†‘
1000â”‚                           â•±â”€â”€â”€ Performance estagna
    â”‚                      â•±â”€â”€â”€â”€
100 â”‚                 â•±â”€â”€â”€â”€
    â”‚            â•±â”€â”€â”€â”€  
10  â”‚       â•±â”€â”€â”€â”€              â† 2004: Ponto de inflexÃ£o
    â”‚  â•±â”€â”€â”€â”€
1   â”‚â”€â”€
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Ano
     1995    2004    2010    2020

Clock (GHz)
4   â”‚         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Clock estagna em ~3-4 GHz
2   â”‚    â•±â”€â”€â”€â”€
1   â”‚â•±â”€â”€â”€â”€
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
```

### AnÃ¡lise por PerÃ­odo

#### Era 1: 1995-2004 (Era Dourada)
- **Crescimento:** 40x em 10 anos
- **Motor:** Aumento exponencial do clock
- **BenefÃ­cio:** Programas ficavam automaticamente mais rÃ¡pidos

#### Era 2: 2004-2020 (Era Multi-Core)
- **Crescimento:** 4x em 16 anos
- **LimitaÃ§Ã£o:** Clock estagnado por limites fÃ­sicos
- **SoluÃ§Ã£o:** MÃºltiplos cores ao invÃ©s de clock mais rÃ¡pido

## ğŸ”¬ Por Que o Clock Parou?

### Limites FÃ­sicos
```
PotÃªncia = CapacitÃ¢ncia Ã— VoltagemÂ² Ã— FrequÃªncia

Aumentar frequÃªncia â†’ Mais calor
Diminuir transistores â†’ Mais vazamento de corrente
Resultado: "Power Wall" em ~4 GHz
```

## ğŸ¯ A SoluÃ§Ã£o: Paralelismo

### De Single-Core para Multi-Core

```
2004: 1 core @ 3.6 GHz = 100% performance
2024: 8 cores @ 3.6 GHz = 800% performance (teÃ³rico)
      
Mas na prÃ¡tica...
Programa tradicional usa apenas 1 core = 100% performance!
```

### Exemplo: CPU AMD (8 Cores)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”â”‚
â”‚ â”‚Coreâ”‚ â”‚Coreâ”‚ â”‚Coreâ”‚ â”‚Coreâ”‚â”‚
â”‚ â”‚ 0  â”‚ â”‚ 1  â”‚ â”‚ 2  â”‚ â”‚ 3  â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜â”‚
â”‚ â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”â”‚
â”‚ â”‚Coreâ”‚ â”‚Coreâ”‚ â”‚Coreâ”‚ â”‚Coreâ”‚â”‚
â”‚ â”‚ 4  â”‚ â”‚ 5  â”‚ â”‚ 6  â”‚ â”‚ 7  â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### GPUs: Paralelismo Extremo
```
CPU: 8-64 cores poderosos
GPU: 1000-10000 cores simples

Filosofia diferente:
CPU = Poucos cavalos de corrida
GPU = Rebanho de ovelhas
```

## ğŸ’¡ O Problema do Paralelismo

### Uso TÃ­pico Multi-Core (Ineficiente para Performance)
```
Core 0: Decodificar vÃ­deo
Core 1: Rede social
Core 2: AntivÃ­rus
Core 3: [idle]
Core 4: [idle]
Core 5: [idle]
Core 6: [idle]
Core 7: [idle]

Sua aplicaÃ§Ã£o cientÃ­fica: Usando apenas Core 0!
```

### O Que Precisamos
```
AplicaÃ§Ã£o Ãºnica usando TODOS os cores:
Core 0: Processar dados[0:1000]
Core 1: Processar dados[1000:2000]
Core 2: Processar dados[2000:3000]
Core 3: Processar dados[3000:4000]
...
Speedup: ~8x!
```

## ğŸ› ï¸ A Promessa dos Algoritmos Paralelos C++

### Antes (Sequencial)
```cpp
// Usa apenas 1 core
transform(data.begin(), data.end(), result.begin(),
          [](float x) { return expensive_computation(x); });
```

### Depois (Paralelo)
```cpp
// Usa TODOS os cores automaticamente!
transform(execution::par, 
          data.begin(), data.end(), result.begin(),
          [](float x) { return expensive_computation(x); });
```

**Uma mudanÃ§a, speedup potencial de 8x!**

## ğŸ“š O Que Vamos Aprender

### 1. Algoritmos Paralelos C++17/20
- `execution::par` - Paralelo em CPU
- `execution::par_unseq` - Paralelo + vetorizado
- `execution::unseq` - Vetorizado (SIMD)

### 2. ExecuÃ§Ã£o em GPU
- Mesmos algoritmos, hardware diferente
- Quando usar CPU vs GPU
- Pitfalls e otimizaÃ§Ãµes

### 3. Problemas Comuns
- Race conditions
- False sharing
- Load balancing
- SincronizaÃ§Ã£o excessiva

## âš ï¸ Armadilhas do Paralelismo

### 1. Nem Tudo Paraleliza
```cpp
// Sequencial por natureza
for(int i = 1; i < n; i++) {
    data[i] = data[i-1] * 2;  // Depende do anterior!
}
```

### 2. Overhead Pode Dominar
```cpp
// Muito pequeno para paralelizar
parallel_for(0, 10, [](int i) {
    result[i] = i * 2;  // Overhead > benefÃ­cio
});
```

### 3. ContenÃ§Ã£o de MemÃ³ria
```cpp
// Todos os cores brigando pela mesma cache line
parallel_for(0, num_cores, [&sum](int i) {
    sum += data[i];  // Race condition + false sharing!
});
```

## ğŸ¯ Quando o Paralelismo Vale a Pena

### CaracterÃ­sticas Ideais:
1. **Granularidade grossa** - Muito trabalho por thread
2. **IndependÃªncia** - Tarefas nÃ£o se comunicam
3. **Load balance** - Trabalho dividido igualmente
4. **Data locality** - Cada core trabalha com seus dados

### Exemplos Perfeitos:
- Processamento de imagem (pixels independentes)
- Monte Carlo (simulaÃ§Ãµes independentes)
- TransformaÃ§Ãµes de array (map, reduce)
- Ãlgebra linear (multiplicaÃ§Ã£o de matrizes)

## ğŸ“Š Expectativas Realistas

### Lei de Amdahl
```
Speedup = 1 / (S + P/N)

S = FraÃ§Ã£o sequencial
P = FraÃ§Ã£o paralela
N = NÃºmero de cores

Exemplo: 95% paralelo, 8 cores
Speedup = 1 / (0.05 + 0.95/8) = 5.9x (nÃ£o 8x!)
```

## ğŸš€ Preview do MÃ³dulo

### O Que Vem Por AÃ­:
1. **Fundamentos** - Como funciona o paralelismo
2. **STL Paralelo** - Algoritmos prontos
3. **GPU Computing** - Milhares de cores
4. **SincronizaÃ§Ã£o** - Evitando bugs
5. **Performance** - Medindo e otimizando
6. **Casos reais** - AplicaÃ§Ãµes cientÃ­ficas

---

**Mensagem Principal:** A era do "almoÃ§o grÃ¡tis" acabou em 2004. Agora, para ganhar performance, vocÃª precisa abraÃ§ar o paralelismo. Este mÃ³dulo mostra como fazer isso de forma eficiente e correta com C++ moderno!