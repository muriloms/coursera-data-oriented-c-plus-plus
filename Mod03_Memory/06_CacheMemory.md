# MemÃ³ria Cache - Material de Estudo Completo

## ğŸ¯ O Problema Fundamental

A CPU opera em nanosegundos, mas a RAM demora centenas de ciclos para responder. Como resolver essa discrepÃ¢ncia? A resposta: **memÃ³ria cache** - um buffer intermediÃ¡rio menor, mas muito mais rÃ¡pido.

## ğŸ—ï¸ Arquitetura do Cache

### VisÃ£o Geral do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CPU   â”‚â†â”€â”€â†’â”‚   L1    â”‚â†â”€â”€â†’â”‚   L2    â”‚â†â”€â”€â†’â”‚   L3    â”‚â†â”€â”€â†’ RAM
â”‚  Core   â”‚    â”‚  Cache  â”‚    â”‚  Cache  â”‚    â”‚  Cache  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†‘ Registradores (bytes)
      32 KB         1 MB         37 MB        394 GB
      1 ns         4 ns         12 ns        100 ns
```

### Como Funciona

```
CPU solicita dado no endereÃ§o 0x1234
                â†“
         L1 Cache tem?
         /          \
       SIM          NÃƒO (L1 miss)
        â†“            â†“
    Retorna      L2 Cache tem?
    (1 ns)       /          \
               SIM          NÃƒO (L2 miss)
                â†“            â†“
            Retorna      L3 Cache tem?
            (4 ns)       /          \
                       SIM          NÃƒO (L3 miss)
                        â†“            â†“
                    Retorna      Busca na RAM
                    (12 ns)      (100 ns)
```

## ğŸ“ PrincÃ­pios de Localidade

### 1. Localidade Temporal
**"Dados acessados recentemente serÃ£o acessados novamente em breve"**

```cpp
// Exemplo: variÃ¡vel usada repetidamente
for(int i = 0; i < 1000000; i++) {
    sum += array[i];  // 'sum' acessado 1 milhÃ£o de vezes
    count++;          // 'count' tambÃ©m
}
```

### 2. Localidade Espacial
**"Dados prÃ³ximos ao acessado serÃ£o acessados em breve"**

```cpp
// Exemplo: processamento sequencial
int array[1000];
for(int i = 0; i < 1000; i++) {
    process(array[i]);  // PrÃ³ximo: array[i+1]
}
```

## ğŸ“¦ Cache Lines - A Unidade Fundamental

### O que Ã© uma Cache Line?

Uma **cache line** Ã© um bloco de dados transferido entre nÃ­veis de memÃ³ria:
- **Tamanho tÃ­pico:** 64 bytes
- **Capacidade:** 16 ints (4 bytes) ou 8 doubles (8 bytes)

```
MemÃ³ria RAM:
â”Œâ”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”
â”‚00â”‚01â”‚02â”‚03â”‚04â”‚05â”‚06â”‚07â”‚08â”‚09â”‚0Aâ”‚0Bâ”‚0Câ”‚0Dâ”‚0Eâ”‚0Fâ”‚...
â””â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”˜
            â†“ Acesso ao endereÃ§o 0x04
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Cache line (64 bytes)       â”‚
    â”‚ EndereÃ§os 0x00 atÃ© 0x3F     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         Todos copiados para cache!
```

### Impacto na Performance

```cpp
// BOM - Aproveita cache line inteira
struct CompactData {
    float x, y, z, w;     // 16 bytes
    float vx, vy, vz, vw; // 16 bytes
    // Total: 32 bytes = meia cache line
};

// RUIM - DesperdiÃ§a cache line
struct SparseData {
    float value;        // 4 bytes
    char padding[60];   // 60 bytes desperdiÃ§ados
    // Total: 64 bytes, mas sÃ³ 4 Ãºteis!
};
```

## ğŸ” Tipos de Cache e Associatividade

### Cache Totalmente Associativo
```
Qualquer bloco pode ir em qualquer linha
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Addr:X â”‚ Addr:Y â”‚ Addr:Z â”‚ Addr:W â”‚
â”‚ Data   â”‚ Data   â”‚ Data   â”‚ Data   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
âœ… FlexÃ­vel  âŒ Busca cara (O(n))
```

### Cache de Mapeamento Direto
```
Cada bloco tem posiÃ§Ã£o fixa
EndereÃ§o % tamanho_cache = posiÃ§Ã£o
âœ… Busca rÃ¡pida  âŒ Conflitos frequentes
```

### Cache Set-Associativo (HÃ­brido)
```
MÃºltiplos conjuntos, cada um parcialmente associativo
Melhor compromisso entre flexibilidade e velocidade
```

## ğŸ“Š Hierarquia de Cache Moderna

### Sistema TÃ­pico Intel (Exemplo do Curso)

| NÃ­vel | Tamanho | LatÃªncia | Compartilhamento | CaracterÃ­sticas |
|-------|---------|----------|------------------|-----------------|
| **L1-D** | 32 KB | ~1 ns | Por core | Dados |
| **L1-I** | 32 KB | ~1 ns | Por core | InstruÃ§Ãµes |
| **L2** | 1 MB | ~4 ns | Por core | Unificado |
| **L3** | 37 MB | ~12 ns | Todos cores | Last Level Cache |
| **RAM** | 394 GB | ~100 ns | Sistema | MemÃ³ria principal |

## âœï¸ OperaÃ§Ãµes de Escrita e Cache Dirty

### Fluxo de Escrita

```cpp
// CPU escreve em endereÃ§o que estÃ¡ em L1
data[i] = 42;
```

```
1. Escrita no L1 Cache
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ L1: valor=42 â”‚ â† Marcado como "dirty"
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
2. RAM ainda tem valor antigo
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ RAM: valor=0 â”‚ â† Desatualizado temporariamente
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
3. Write-back quando necessÃ¡rio
   - Quando linha Ã© removida do cache
   - Quando explicitamente sincronizado
```

### Cascata de Write-backs

```
L1 Miss â†’ Precisa evict linha dirty
         â†“
    Write-back para L2
         â†“
    L2 cheio? â†’ Evict linha L2
         â†“
    Write-back para L3
         â†“
    L3 cheio? â†’ Evict linha L3
         â†“
    Write-back para RAM
    
Resultado: Um simples read pode causar mÃºltiplos writes!
```

## ğŸ’» CÃ³digo Exemplo: Impacto do Cache

```cpp
#include <iostream>
#include <vector>
#include <chrono>
#include <cstring>

class CacheDemo {
private:
    using Clock = std::chrono::high_resolution_clock;
    static constexpr size_t CACHE_LINE_SIZE = 64;
    
public:
    // Demonstra false sharing
    struct BadAlignment {
        alignas(64) int counter1;  // Thread 1
        int counter2;              // Thread 2 - mesma cache line!
    };
    
    struct GoodAlignment {
        alignas(64) int counter1;  // Thread 1
        alignas(64) int counter2;  // Thread 2 - cache lines diferentes
    };
    
    // Demonstra travessia de matriz
    static void row_major_traversal(int** matrix, int size) {
        int sum = 0;
        for(int i = 0; i < size; i++) {
            for(int j = 0; j < size; j++) {
                sum += matrix[i][j];  // Acesso sequencial na memÃ³ria
            }
        }
    }
    
    static void column_major_traversal(int** matrix, int size) {
        int sum = 0;
        for(int j = 0; j < size; j++) {
            for(int i = 0; i < size; i++) {
                sum += matrix[i][j];  // Pula entre linhas - cache misses!
            }
        }
    }
    
    // Demonstra cache blocking
    static void matrix_multiply_naive(float** A, float** B, float** C, int n) {
        for(int i = 0; i < n; i++) {
            for(int j = 0; j < n; j++) {
                for(int k = 0; k < n; k++) {
                    C[i][j] += A[i][k] * B[k][j];
                }
            }
        }
    }
    
    static void matrix_multiply_blocked(float** A, float** B, float** C, int n) {
        const int BLOCK = 64;  // Ajustado para cache L1
        
        for(int ii = 0; ii < n; ii += BLOCK) {
            for(int jj = 0; jj < n; jj += BLOCK) {
                for(int kk = 0; kk < n; kk += BLOCK) {
                    // Mini multiplicaÃ§Ã£o que cabe em cache
                    for(int i = ii; i < std::min(ii + BLOCK, n); i++) {
                        for(int j = jj; j < std::min(jj + BLOCK, n); j++) {
                            for(int k = kk; k < std::min(kk + BLOCK, n); k++) {
                                C[i][j] += A[i][k] * B[k][j];
                            }
                        }
                    }
                }
            }
        }
    }
};

// Exemplo de uso eficiente de cache
class CacheFriendlyContainer {
private:
    struct Node {
        int data[15];        // 60 bytes de dados Ãºteis
        Node* next;          // 8 bytes ponteiro
        // Total: 68 bytes, mas alinhado em 64 (cache line)
    } __attribute__((packed, aligned(64)));
    
    std::vector<Node> nodes;  // AlocaÃ§Ã£o contÃ­gua
    
public:
    void process_all() {
        // Percorre sequencialmente - cache friendly
        for(auto& node : nodes) {
            for(int i = 0; i < 15; i++) {
                node.data[i] *= 2;
            }
        }
    }
};
```

## ğŸ¯ OtimizaÃ§Ãµes Cache-Aware

### 1. Loop Tiling/Blocking
```cpp
// Processa dados em blocos que cabem em cache
void process_large_array(float* data, size_t size) {
    const size_t L1_SIZE = 32 * 1024 / sizeof(float);
    
    for(size_t block = 0; block < size; block += L1_SIZE) {
        size_t end = std::min(block + L1_SIZE, size);
        
        // Tudo cabe em L1
        for(size_t i = block; i < end; i++) {
            data[i] = complex_computation(data[i]);
        }
    }
}
```

### 2. Padding para Evitar Conflitos
```cpp
// Evita que arrays mapeiem para mesmas linhas de cache
class OptimizedMatrix {
    static constexpr int ROWS = 1024;
    static constexpr int COLS = 1024;
    static constexpr int PAD = 1;  // Evita power-of-2
    
    float data[ROWS][COLS + PAD];  // Padding previne conflitos
};
```

### 3. Prefetching
```cpp
void process_with_prefetch(int* data, size_t size) {
    for(size_t i = 0; i < size; i++) {
        // Dica para CPU trazer prÃ³ximos dados
        __builtin_prefetch(&data[i + 8], 0, 3);
        
        // Processa dado atual
        result[i] = heavy_computation(data[i]);
    }
}
```

## ğŸ“ˆ MÃ©tricas de Performance

### Como Medir Cache Performance

```bash
# Linux - usando perf
perf stat -e cache-references,cache-misses ./program

# MÃ©tricas importantes:
# - Cache hit ratio: (hits / (hits + misses)) * 100
# - Miss penalty: ciclos perdidos por miss
# - Bandwidth utilization: bytes/segundo usado vs disponÃ­vel
```

## ğŸ“ Conceitos-Chave

1. **Cache Line:** Unidade de transferÃªncia (64 bytes)
2. **Cache Miss:** Dado nÃ£o encontrado, busca nÃ­vel acima
3. **Cache Hit:** Dado encontrado, acesso rÃ¡pido
4. **Dirty Line:** Modificada mas nÃ£o sincronizada
5. **Eviction:** RemoÃ§Ã£o de linha para abrir espaÃ§o
6. **Write-back:** SincronizaÃ§Ã£o de dados dirty
7. **Localidade:** Temporal e espacial

## ğŸ’¡ Dicas PrÃ¡ticas

### DO's âœ…
- Acesse dados sequencialmente
- Agrupe dados relacionados
- Use estruturas de tamanho power-of-2 com cuidado
- Processe dados em blocos cache-sized
- Alinhe estruturas crÃ­ticas em cache lines

### DON'Ts âŒ
- Evite stride patterns grandes
- NÃ£o desperdice espaÃ§o em cache lines
- Evite false sharing em cÃ³digo paralelo
- NÃ£o ignore localidade de referÃªncia

## ğŸ” ExercÃ­cios

### ExercÃ­cio 1: Cache Line Analysis
Quantas cache lines sÃ£o necessÃ¡rias para:
```cpp
struct Data {
    double values[100];  // 800 bytes
    int flags[50];       // 200 bytes
};
```

### ExercÃ­cio 2: OtimizaÃ§Ã£o
Reescreva para melhor uso de cache:
```cpp
for(int i = 0; i < 1000; i++) {
    a[i] = b[i * 100] + c[i * 100];
}
```

### ExercÃ­cio 3: False Sharing
Identifique e corrija o problema:
```cpp
struct Counters {
    int thread1_count;
    int thread2_count;
};
```

## ğŸ¯ ConclusÃ£o

O cache Ã© fundamental para performance moderna. A diferenÃ§a entre cÃ³digo cache-friendly e cache-unfriendly pode ser 10x, 100x ou mais! 

**Lembre-se:** 
- Cache nÃ£o Ã© mÃ¡gica - funciona com padrÃµes previsÃ­veis
- Localidade Ã© a chave - temporal e espacial
- Hierarquia existe por uma razÃ£o - use cada nÃ­vel eficientemente
- Medir Ã© essencial - nÃ£o adivinhe, profile!

---

ğŸ’­ **ReflexÃ£o Final:** Um programador que entende cache pode fazer um Core i3 superar um Core i9 mal utilizado. O hardware moderno Ã© incrivelmente poderoso, mas sÃ³ entrega essa potÃªncia para quem sabe usÃ¡-lo!
